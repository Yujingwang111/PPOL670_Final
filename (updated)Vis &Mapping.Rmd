---
title: "Predicative Crime of D.C."
author: "Selina Sun"
date: "5/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#data wrangling and pre-processing
library(tidyverse)
library(plyr)
library(dplyr)
library(readr)
library(purrr)
library(lubridate)
library(hms)
library(janitor)
#mapping 
library(sf)
library(viridis)
library(tigris)
library(ggspatial)
library(patchwork)
#getting census tract data
library(tidycensus)
library(httr)
library(dotenv)
#machine
library(recipes)
library(tidymodels)
library(glmnet)
library(caret)
library(vip)
library(parsnip)
library(randomForest)
library(ranger)
library(rpart)
#time series analysis 
library(plotly)
library(TSstudio)
library(forecast)
library(MLmetrics)
#read and load DC crimes data from 2017-2021
crimes <-
  list.files(path = "data/",
             pattern = "*.csv", 
             full.names = T) %>% 
  map_df(~read_csv(., col_types = cols("CCN"= col_double(),
                                       "LONGITUDE" = col_character(),
                                       "LATITUDE" = col_character()))) 
```

#1.Crime data:data wrangling and pre-processing
```{r dc_crime}
#change case of the variables
change_case<-function(x){
  return(gsub("\\b([A-Z])([A-Z]+)", "\\U\\1\\L\\2", x, perl=TRUE))
}
#change case and split date variable to weekdays, month and year, label property offense 
crimes<-crimes%>%
  clean_names()%>%
  dplyr::mutate(shift=change_case(shift),
                method=change_case(method),
                offense=change_case(offense),
                block=change_case(block),
                bid=change_case(bid),
                weekday=lubridate::wday((report_dat), label=TRUE),
                month=lubridate::month((report_dat),label=TRUE),
                year=lubridate::year(report_dat),
                day=lubridate::day(report_dat),
                rep_date=date(report_dat),
                rep_time=hms::as_hms(ymd_hms(report_dat)),
                hours=lubridate::hour(rep_time),
                autotheft=ifelse(offense=="Theft F/Auto", 1, 0))%>%
  mutate(autotheft=as.factor(autotheft))%>%
  as_tibble()

#identify duplication incidents by CCN
crimes%>%
  group_by(ccn)%>%
  dplyr::mutate(count=n())%>%
  filter(count>1)
#remove duplicate rows 
crimes_clean<-filter(distinct(crimes, ccn, .keep_all = TRUE))
#check 
crimes_clean%>%
  group_by(ccn)%>%
  dplyr::mutate(count=n())%>%
  filter(count>1)
#overview of crime data
crimes_clean%>%
  group_by(offense)%>%
  dplyr::summarize(count=n())%>%
  arrange(desc(count))
#calculate frequency by offense 
crimes_clean%>%
  group_by(offense)%>%
  dplyr::summarise(count=sum(ccn, na.rm = TRUE))%>%
  mutate(freq=100*count/sum(count,na.rm = TRUE))%>%
  arrange(desc(freq))%>%
  ungroup()

#sf theft to join
crimes_sf <- st_as_sf(
  crimes_clean, 
  coords = c("longitude", "latitude"), 
  crs = 4326
)
```
In the table below, we observe that THEFT comprises about 70% of total crimes in the historical dataset. It represents over ??? observations from 2017 to 2021. This is a sufficiently rich dataset for predictive analysis.
#City limits
```{r}
#DC limits
#load the census tracts of dc
#unzip(zipfile="data/Census_Tracts_in_2020.zip",
      #exdir = "data")
#read shapefile into sf
dc_sf<-st_read("data/Census_Tracts_in_2020.shp")%>%
  clean_names()%>%
  select(geoid, geometry,tract)%>%
  st_transform(crs=4326)
```
#Census Tracts variables poverty, pop dens and unemployment
#### Getting Census Tracts through API
```{r}
readRenviron("~/.Renviron")
credential<- Sys.getenv("census_api_key")
#find variable code and select variables
v2020 <- load_variables(2020, "acs5", cache = TRUE)
#population B01003_001
#poverty B17017_001
#unemployment B23025_001
#household income B19013_001
#getting variables from acs
options(tigris_use_cache = TRUE)
dc_acs<-as_tibble(get_acs(
  geography = "tract",
  survey="acs5",
  variables = c("B01003_001","B17017_001","B17017_002", "B23025_001",
  "B23025_005", "B19013_001","B06009_001", "B06009_002"),
  state=11,
  county=001,
  geometry=TRUE,
  year=2020,
))
#data wrangling and preprocessing 
#pivot tibbles and rename variables to get demographic features of dc
dc_demo<-dc_acs%>%
  clean_names()%>%
  select(geoid, variable, estimate, geometry)%>%
  pivot_wider(
    names_from = "variable", 
    values_from = "estimate")%>%
  dplyr::rename(population=B01003_001,
                poverty_raw=B17017_001,
                poverty_below=B17017_002,
                employ=B23025_001,
                unemploy=B23025_005,
                income=B19013_001,
                educ=B06009_001,
                belowhigh=B06009_002)%>%
  #handling missing data with average values
  mutate(avg_poverty_rate=poverty_below/poverty_raw, #extract regional average poverty rate
         avg_poverty_rate=ifelse(poverty_raw == 0, 0, poverty_below/poverty_raw),#impute missing data
         avg_unemploy_rate=unemploy/employ,#extract regional average poverty rate
         avg_unemploy_rate=ifelse(employ==0, avg_unemploy_rate, unemploy/employ),#impute missing data
         income=ifelse(is.na(income) | income==0, 98654, income), #median household income for missing data
         population=ifelse(is.na(population), 0, population),
         below_high=belowhigh/educ, #regional below high school educ
         below_high=ifelse(is.na(educ), 0, belowhigh/educ))#impute missing 
```
#join census tract data with crime data 
```{r}
data<-st_join(crimes_sf, dc_sf, join=st_intersects)
data<-left_join(data, dc_demo, by="geoid")%>%
  st_set_geometry(NULL)
sample<-data%>%
  select(shift, ward, psa, block_group, 
         weekday, month,year,hours,
         autotheft,population,income, 
         avg_poverty_rate,avg_unemploy_rate,below_high)%>%
  mutate(autotheft=as.factor(autotheft))
write_csv(sample,"sample.csv")
```

#Simple decision tree model (the only one that succeed)
```{r}
set.seed(20220502)
split<-initial_split(sample, prop=0.75)
theft_train<-training(split)
theft_test<-testing(split)
theft_rec<-
  recipe(autotheft ~ ., data = theft_train) %>%
  themis::step_downsample(autotheft)%>%
  prep(training=theft_train, retain = TRUE)

sampled_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")
sampled_wf <- workflow() %>%
  add_recipe(theft_rec) %>%
  add_model(sampled_mod) 
#fit the model
sampled_fit <- sampled_wf %>%
  fit(data = theft_train)
#plot a decision tree
rpart.plot::rpart.plot(x = sampled_fit$fit$fit$fit)
```
```{r}
predictions <- bind_cols(
  theft_test,
  predict(object = sampled_fit, new_data = theft_test),
  predict(object = sampled_fit, new_data = theft_test, type = "prob")
)
select(predictions, autotheft, starts_with(".pred"))

conf_mat(data = predictions,
         truth = autotheft,
         estimate = .pred_class)
yardstick::accuracy(data = predictions,
         truth = autotheft,
         estimate = .pred_class)
yardstick::recall(data = predictions,
       truth = autotheft,
       estimate = .pred_class)
sampled_fit%>%
  extract_fit_parsnip() %>%
  vip(num_features = 10)
```
#Reflection and Improvement

===================================================
Failed logistic classification model - binominal 
lr_recipe <- 
  recipe(autotheft ~ ., data = theft_train) %>% 
  step_other(ward, block_group, psa)%>%
  step_r(month, weekday)%>%
  step_dummy(year,hour,ward) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
bake(prep(lr_recipe, training = theft_train), new_data = theft_train)
folds <- vfold_cv(data = theft_train, v = 10, repeats = 1)
```

Failed model for decision tree with tuning 
dt_mod<-
  decision_tree(cost_complexity = tune(),
                tree_depth=tune(),
                min_n=tune())%>%
  set_engine(engine = "rpart")%>%
  set_mode(mode="classification")
dt_wf<-workflow()%>%
  add_recipe(theft_rec)%>%
  add_model(dt_mod)
dt_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 3)
set.seed(20220502)
dt_tuning<-dt_wf %>%
  tune_grid(resamples=folds,
            grid=dt_grid)
#plot the rmse for decision tree
collect_metrics(dt_tuning, summarize = FALSE)%>%
  filter(.metric == "rmse")%>%
  ggplot(aes(id, .estimate, group= .estimator))+
  geom_line()+
  geom_point()+
  scale_y_continuous(limits = c(0, 3)) +
  labs(title = "Calculated RMSE Across the 10 Folds",
     y = "RMSE_hat") +
theme_minimal()
dt_tuning%>%
  show_best(metric="rmse")
dt_best <- dt_tuning %>%
  select_best(metric="rmse")
dt_final <- finalize_workflow(
  dt_wf,
  parameters = dt_best
)
dt_final <- finalize_workflow(
  dt_wf,
  parameters = dt_best
)
dt_wf_fit<-dt_final%>%
  fit(data=theft_train)
dt_fit<-dt_wf_fit%>%
  pull_workflow_fit()
dt_coefs <- dt_final %>%
  fit(data = theft_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = dt_best)
vip(dt_fit)
===========================================

#We also tried some Time series Analysis
For Time Series Analysis, we choose one type of crime, Auto theft based on 2017 to 2021 data.
```{r}
#extract day and the number of theft, set interval unit to hours
crimes_theft<-crimes_clean%>%
  select(offense, year, month, day, hours)%>%
  mutate(Date=make_datetime(year, month, day, hours))%>%
  select(offense,Date)%>%
  filter(offense=="Theft F/Auto")%>%
  group_by(Date)%>%
  dplyr::summarise(Theft=n())%>%
  ungroup()
#check the begining and ending of the time frame
head(crimes_theft,10) 
tail(crime_theft, 20)
```

#Cross Validation
Time series object will be based on the Battery column and the frequency to be 24 as it is total hour of reported crime for 1 day.
```{r}
#creat object
theft_ts <- ts(crimes_theft$Theft, frequency = 24)
#plot the number of theft according to date
theft_plot <-crimes_theft %>%
ggplot(aes(x = Date, y = Theft)) +
geom_line(aes(color = "Theft")) +
scale_x_datetime(name = "Date", date_breaks = "5 year") +
scale_y_continuous(breaks = seq(0, 400, 100)) + 
theme_minimal() +
labs(title = "DC Theft Crime", subtitle = "2017 - 2021")
ggplotly(theft_plot)
```

```{r}
#decompose time series object 
#try to see the trend and seasonality 
theft_ts_dec <- theft_ts %>%
  tail(365) %>%
  decompose()
theft_ts_dec %>%
  autoplot()
```
The trend shows some pattern like seasonal, indicating there are other seasonality pattern that have not been caught by the plot. We will create a Multi Seasonal Time Series Object.

```{r}
# Create MSTS Object
theft_multi <- msts(crimes_theft$Theft, seasonal.periods = c(24, # Daily
                                                            24*7, # Weekly
                                                            24*30)) # Monthly
# Decompose MSTS Object
theft_multi_dec <- theft_multi %>%
  mstl()

theft_multi_dec %>%
  tail(365) %>%
  autoplot()
```
From the plot above, we can see the trend of the theft Crime is already going smooth. The theft Crime trend itself is decreasing in the last 365 days.

#Seasonality Analysis 
##Daily Seasonality
These are the plot of Daily Seasonality of Battery Crime in Chicago
```{r}
# Create a data frame based on MSTS Object
theft_multi_df <- as.data.frame(theft_multi_dec)
p1 <- theft_multi_df %>%
  mutate(day = crimes_theft$Date) %>%
  group_by(day) %>%
  summarise(seasonal = sum(Seasonal24 + Seasonal168 + Seasonal720)) %>%
  head(24*2) %>%
  ggplot(aes(x = day, y = seasonal)) +
  geom_point(col = "red") + geom_line(col = "black") +
  theme_minimal()
p2 <- theft_multi_df %>%
  mutate(day = crimes_theft$Date, 
         month = month(crimes_theft$Date, label = T)) %>%
  group_by(month) %>%
  summarise(seasonal = sum(Seasonal24 + Seasonal168 + Seasonal720)) %>%
  head(24*30) %>%
  ggplot(aes(x = month, y = seasonal)) +
  geom_point() + geom_col() +
  theme_minimal()
p1/p2
```
As we can see from the plot above, The crime tend to increase in the month of Feb, May, July, and Nov. These can be seen as a warning signal to people around the city that the chance of them getting harmed is high around these time. .
